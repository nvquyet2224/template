<!DOCTYPE html>
<html lang="vi">
<meta name="viewport"
    content="width=device-width, initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=6.0">
<meta name="format-detection" content="telephone=no">

<head>
    <title>Multiple object detection using pre trained model in TensorFlow.js</title>
    <meta charset="utf-8">
    <link href="style.css" rel="stylesheet" rel="preload" as="style">
</head>

<body>

    <section id="demos" class="video__box">
        <div id="liveView" class="camView">
            <video id="webcam" playsinline></video>
            <div class="loading__message">Loading...</div>
        </div>
    </section>

    <!-- Import TensorFlow.js library -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>
    <!-- Load the coco-ssd model to use to recognize things in images -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <!-- Import the page's JavaScript to do some stuff -->
    <script>
        let video = document.getElementById('webcam');
        const liveView = document.getElementById('liveView');
        //const demosSection = document.getElementById('demos');
        //const enableWebcamButton = document.getElementById('webcamButton');
        const videoWidth = 300;
        const videoHeight = 300;
        //var currentFlipCamera = 'environment';
        var currentFlipCamera = 'user';
        

        // Check if webcam access is supported.
        function getUserMediaSupported() {
            return !!(navigator.mediaDevices &&
                navigator.mediaDevices.getUserMedia);
        }

        // If webcam supported, add event listener to button for when user
        // wants to activate it to call enableCam function which we will 
        // define in the next step.

        if (getUserMediaSupported()) {
            //enableWebcamButton.addEventListener('click', enableCam);
        } else {
            console.warn('getUserMedia() is not supported by your browser');
        }

        async function setupCamera() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                throw new Error(
                    'Browser API navigator.mediaDevices.getUserMedia not available');
            }

            //video.width = videoWidth;
            //video.height = videoHeight;

            const stream = await navigator.mediaDevices.getUserMedia({
                'audio': false,
                'video': {
                    facingMode: currentFlipCamera,
                    //width: videoWidth,
                    //height: videoHeight,
                },
            });

            video.srcObject = stream;
            //video.addEventListener('loadeddata', predictWebcam);
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function flip_camera() {
            currentFlipCamera = currentFlipCamera == 'environment' ? 'user' : 'environment';
            enableCam();
        }

        // Enable the live webcam view and start classification.
        async function enableCam() {
            // Only continue if the COCO-SSD has finished loading.
            
            if (!model) {
                return;
            }

            // Hide the button once clicked.
            //event.target.classList.add('removed');  

            // getUsermedia parameters to force video but not audio.
            /*const constraints = {
                audio: false,
                video: true
            };*/

            // Activate the webcam stream.
            /*navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                video.srcObject = stream;
                video.addEventListener('loadeddata', predictWebcam);
            });*/

            console.log('enableCam');
            video = await setupCamera();
            video.play();
        }

        // Store the resulting model in the global scope of our app.
        var model = undefined;

        // Before we can use COCO-SSD class we must wait for it to finish
        // loading. Machine Learning models can be large and take a moment 
        // to get everything needed to run.
        // Note: cocoSsd is an external object loaded from our index.html
        // script tag import so ignore any warning in Glitch.
        cocoSsd.load().then(function (loadedModel) {
            model = loadedModel;
            console.log('model loaded');
            enableCam();
            // Show demo section now model is ready to use.
            //demosSection.classList.remove('invisible');
        });

        var children = [];

        function predictWebcam() {
            // Now let's start classifying a frame in the stream.
            model.detect(video).then(function (predictions) {
                // Remove any highlighting we did previous frame.
                for (let i = 0; i < children.length; i++) {
                    liveView.removeChild(children[i]);
                }
                children.splice(0);

                // Now lets loop through predictions and draw them to the live view if
                // they have a high confidence score.
                for (let n = 0; n < predictions.length; n++) {
                    // If we are over 66% sure we are sure we classified it right, draw it!
                    if (predictions[n].score > 0.66) {
                        const p = document.createElement('p');
                        p.innerText = predictions[n].class + ' - with '
                            + Math.round(parseFloat(predictions[n].score) * 100)
                            + '% confidence.';
                        p.style = 'margin-left: ' + predictions[n].bbox[0] + 'px; margin-top: '
                            + (predictions[n].bbox[1] - 10) + 'px; width: '
                            + (predictions[n].bbox[2] - 10) + 'px; top: 0; left: 0;';

                        const highlighter = document.createElement('div');
                        highlighter.setAttribute('class', 'highlighter');
                        highlighter.style = 'left: ' + predictions[n].bbox[0] + 'px; top: '
                            + predictions[n].bbox[1] + 'px; width: '
                            + predictions[n].bbox[2] + 'px; height: '
                            + predictions[n].bbox[3] + 'px;';

                        liveView.appendChild(highlighter);
                        liveView.appendChild(p);
                        children.push(highlighter);
                        children.push(p);
                    }
                }

                // Call this function again to keep predicting when the browser is ready.
                window.requestAnimationFrame(predictWebcam);
            });
        }

        //enableCam();

    </script>
</body>

</html>